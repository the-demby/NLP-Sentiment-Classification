# ğŸ§ NLP Sentiment Classification â€“ IMDB Project

This project is part of the final evaluation for the NLP course. It investigates how classical and transformer-based models handle binary sentiment classification on the IMDB dataset, with a focus on the integration of lexicon-based polarity scores.

---

## ğŸ—‚ï¸ Project Structure

```
NLP-Sentiment-Classification/
â”‚
â”œâ”€â”€ Data/                  # Raw and cleaned datasets (excluded from Git)
â”‚   â”œâ”€â”€ imdb_cleaned.csv
â”‚   â””â”€â”€ svm_preds.npz
â”‚
â”œâ”€â”€ results/               # Model outputs (excluded from Git)
â”œâ”€â”€ notebooks/             # Jupyter notebooks for each experiment phase
â”‚   â”œâ”€â”€ data_exploration.ipynb
â”‚   â”œâ”€â”€ preprocessing.ipynb
â”‚   â”œâ”€â”€ baseline_training.ipynb
â”‚   â”œâ”€â”€ bert_finetuning.ipynb
â”‚   â””â”€â”€ comparative_analysis.ipynb
â”‚
â”œâ”€â”€ src/                   # All source code (modularized)
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ nltk_utils.py
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”œâ”€â”€ data_loading.py
â”‚   â”œâ”€â”€ preprocessing.py
â”‚   â”œâ”€â”€ vectorization.py
â”‚   â”œâ”€â”€ baseline_model.py
â”‚   â”œâ”€â”€ bert_model.py
â”‚   â”œâ”€â”€ bert_preparation.py
â”‚   â””â”€â”€ er_lexicon.py
â”‚
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ install.sh
â”œâ”€â”€ .gitignore
â””â”€â”€ A_Comparative_Analysis_of_SVM_and_DistilBERT_with_Polarity_aware_Features.pdf
```

---

## âš™ï¸ Installation

You can install the environment in one line using the `install.sh` script:

```bash
bash install.sh
```

Alternatively, manually:

```bash
python3 -m venv env
source env/bin/activate
pip install -r requirements.txt
```

---

## ğŸ§ª Project Phases

| Phase                            | Notebook                     |
| -------------------------------- | ---------------------------- |
| ğŸŠ Data exploration & statistics | `data_exploration.ipynb`     |
| ğŸ§¹ Text cleaning & ER scoring    | `preprocessing.ipynb`        |
| ğŸ“Š TF-IDF + SVM Baseline         | `baseline_training.ipynb`    |
| ğŸ¤– DistilBERT fine-tuning        | `bert_finetuning.ipynb`      |
| ğŸ” Error analysis & comparison   | `comparative_analysis.ipynb` |

---

## ğŸ”¬ Key Findings

* **DistilBERT** achieves **90.7% accuracy**, outperforming TF-IDF + SVM (89.3%)
* Adding `er_score` improves SVM slightly, but degrades BERT
* Embedding space visualizations show clear sentiment clustering
* Error analysis reveals that BERT handles subtle context well but underperforms on short, polarized reviews

---

## ğŸ“ Final Report

The complete article, following the NeurIPS 2024 format, is included as a PDF:

ğŸ“„ [`A_Comparative_Analysis_of_SVM_and_DistilBERT_with_Polarity_aware_Features.pdf`](./A_Comparative_Analysis_of_SVM_and_DistilBERT_with_Polarity_aware_Features.pdf)

---

## ğŸ‘¤ Author

**\[Ismael DEMBELE]** - MS DS
This project was conducted as part of the final evaluation for the \[ENSAE NLP Course, 2025].
# NLP-Sentiment-Classification